[{"content":"intro In this post we will take look at a simple heap overflow vulnerability and exploit the binary. The goal of this challenge to execute the shell function by exploiting the heapoverflow vulnerability.\nBinary Info You can see the information about the binary in the above image. i have recompiled this binary from the source code and disabled the stack canary and pie (Position Independent Executable) so that address of function does not change dynamicly every time we execute the binary..\nCode Analysis #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; struct data{ char string[0x20]; }; struct funcpointer{ void (*fp)(); char __pad[64 - sizeof(unsigned long)]; }; void shell() { system(\u0026#34;/bin/bash\u0026#34;); } void exploit(){ printf(\u0026#34;Exploit is completed, But where is the Shell \u0026gt;_\u0026lt;\\n\u0026#34;); } void fail(){ printf(\u0026#34;Looks like Your exploit did not worked this time!\\n\u0026#34;); } void vuln(char arg[]) { struct data *value; struct funcpointer *f; value = malloc(sizeof(struct data)); f = malloc(sizeof(struct funcpointer)); f-\u0026gt;fp = NULL; strcpy(value-\u0026gt;string,arg); if (strncmp(value-\u0026gt;string, \u0026#34;exploited\u0026#34;, 9) == 0) { f-\u0026gt;fp = exploit; } printf(\u0026#34;data is at %p, fp is at %p, will be calling %p\\n\u0026#34;, value, f, f-\u0026gt;fp); free(value); if (f-\u0026gt;fp) { f-\u0026gt;fp(); } else { fail(); ** } } int main(int argc, char** argv) { if( argc \u0026lt; 2 ){ printf(\u0026#34;Enter the a string as agument\\n\u0026#34;); return -1; } vuln(argv[1]); return 0; } So there are some function like sehll exploit fail vuln and main\nIn the main function we call the vuln and pass a command line argument to it.\nlets look at the vuln function. In the first two line we see the variables of the structures are being create one is value and f and after that the memory is allocated for the structures. In the next line the NULL value is assigned to the function pointer f-\u0026gt;fp = NULL;\nNow in the next line using the strcpy function the argument which we passed is being copied to the string variable which is member of the data struct.\nIn the next line a comparison is taking place it compares the value of the string variable to exploited and it only compare the first 9 character of the string variable. if the comperison is success it assigns the address of exploit function to the function pointer like this f-\u0026gt;fp = exploit\nIn the next line it prints some data like the address of the data and fp structures and the address of the function which is stored in the function pointer and will be called.\nIn the if else block if the function pointer hold some value and its not empty which means if it points to some function then it executes that function or if it dose not points to any function it will call the fail function.\nDebugging By running and passing a string argument to the binary we see it works as expected.\nThe string comparison fails and because the function pointer is assigned to the null so the else block executes and call the fail function.\nNow the string comparison is passed we can see it assigned the address of exploit function to the function pointer and now the if block is true which means the function pointer is not null or empty it holds some address and then f-\u0026gt;fp(); invokes the exploit function.\nSo now we have a clear understanding of the binary so how do we execute shell function and get a shell. One thing we can do is we can over flow the heap and overwrite the function pointers value because if you look at the strcpy function there is no string length check is being performed which means you can provide arbitrary length of input data and it strcpy will copy it to the heap which will cause an overflow.\nRabbitHole of exploited So as we know that the strncmp function only check the first 9 character of our input let\u0026rsquo;s try to input exploited followed by multiple a something like this exploitedaaaaaaaaaaa.....\nhmmmm. it doesn’t look like we are able to overflow the heap chunk lets give it some more a’s\nLooks like we overflowed the heap and corrupted the top chunk’s size field but why we are able to overwrite the topcunk’s size field but not the function pointer. Because without overwriting the functionpointer chunk we can not overwrite the topchuck but we did overwrite the topchunk. we overflowed the function pointer so we as we know it should point at the 0x6161616161616161 but still it points at 0x401210 which is the address of exploit function why this is happening. lets see why\nso we can see we have two chunks the one will hold over string and other one holds the function pointer’s value.\nso the now co to the strcpy instruction and see how over help looks like after the strcpy is done.\nYou can see we did overflow the function pointer which is at 0x4052d0 and the value is 0x61616161 Now lets step up and see why the program behave differently.\nThe strncmp compare the first 9 character of our input to exploited and if it is equal the it will change the function pointer to exploit function according to the programs logic.\nif (strncmp(value-\u0026gt;string, \u0026#34;exploited\u0026#34;, 9) == 0) { f-\u0026gt;fp = exploit; } Here it gets intersting and so even we overwrite the funtion pointer in the starting as the programm progress and gets to strncmp condition. it will again overwrite the fuction pointer to exploit function.\nSee the address 0x4052d0 holds the address of exploit function which is 0x401210.\nAnd after that the program works as expected it checks weather the function pointer holds some value. Then it execute that function pointer.\nThat’s why the program was always executed the exploit function.\nExploitation How do we exploit this? you may be asking the answer is very simple we don’t have to pass the strcnmp check because if we pass the check eventually the program will change the value of function pointer to exploit which we don’t want to.\nso lets try something different insted of passing exploited wee will pass bunch of A's\nNow we get over lovely segfault because over function pointer calls the 0x61616161616161 which is not a valid address and that’s why we get segfault. So the exploitation phases is very easy we just have to calculate how many bytes we have to overwrite so we can write the address shell function to the function pointer.\nThere are two ways to calculate the address you can choose any one you like i will show you the both.\nUsing the cyclic pattern\nUsing Heap Layout\nOver input gets written at 0x4052a0 and the function pointer value stored at 0x4052d0 if we minus 0x4052d0 - 0x4052a0 we get 0x30 which converted to integer is 48 so we need to pass 48 A followed by the address of shell function.\nExploit #!/bin/python3 from pwn import * context(os=\u0026#34;linux\u0026#34;,arch=\u0026#34;amd64\u0026#34;) binary = \u0026#34;./overflow\u0026#34; elf = ELF(binary) payload = (b\u0026#39;A\u0026#39;* 48 + flat(elf.sym[\u0026#39;shell\u0026#39;])).replace(b\u0026#39;\\x00\u0026#39;,b\u0026#39;\u0026#39;) target = elf.process(argv=[payload]) print(target.clean().decode(\u0026#39;utf-8\u0026#39;)) target.interactive() In this exploit i used the elf function of pwn tools which help me to get the address of shell function which is 0x4011f6 I use the elf function it make my exploitation process very easy.\nLets execute the exploit and see are did i worte the correct exploit\nBoom!! it worked in the first try. you can see the exploit is successfull and i got the shell.\n","permalink":"http://localhost:1313/posts/heapexp3/","summary":"\u003ch3 id=\"intro\"\u003e\u003cstrong\u003eintro\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eIn this post we will take look at a simple heap overflow vulnerability and exploit the binary. The goal of this challenge to execute the shell function by exploiting the heapoverflow vulnerability.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"binary-info\"\u003e\u003cstrong\u003eBinary Info\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"Screenshot at 2024-09-26 12-50-04.png\" loading=\"lazy\" src=\"Heap%20Exploitation%20Part%203%20%7BHeap%20Overflow%7D%2039636a134fcd474aa1c13f9990b1fb87/Screenshot_at_2024-09-26_12-50-04.png\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can see the information about the binary in the above image. i have recompiled this binary from the source code and disabled the stack canary and pie (Position Independent Executable) so that address of function does not change dynamicly every time we execute the binary..\u003c/p\u003e","title":"Heap Exploitation Part 3"},{"content":"Intro Welcome back to the second part of the Heap Exploitation Series. In the previous part, I provided a basic overview of glibc’s heap implementation. If you haven\u0026rsquo;t read that part yet, I highly recommend you go back and check it out to understand fundamental concepts such as chunks and bins. However, if you are already familiar with these basics, you can continue reading here. In this post, we will delve deeper into the process of memory allocation and deallocation in glibc’s heap. We’ll explore how memory is allocated for a process and the mechanisms involved in freeing memory.\nBasics Memory Allocation When you request memory for your program, for example, 0x10 bytes of memory, by calling malloc, it returns a pointer to the allocated memory space where you can store your data. However, the allocation process involves more than simply providing 16 bytes of free memory space.\nThe heap manager performs several additional tasks behind the scenes. It keeps track of all allocated memory chunks by storing metadata alongside the user-requested space. This metadata includes information such as the size of the allocated chunk and its status (e.g., whether it is free or in use). Additionally, the heap manager ensures proper memory alignment for better efficiency. On 32-bit systems, memory is typically aligned to 0x8 (8) bytes, while on 64-bit systems, it is aligned to 0x10 (16) bytes.\nWhen you request 0x10 (16) bytes of memory, the heap manager actually allocates more than just 16 bytes. In practice, it typically allocates a total of 32 bytes. This allocation includes 16 bytes for metadata or a header, which contains information about the allocated chunk, such as its size and status. Additionally, it includes the 16 bytes you requested for storing your data. To ensure proper alignment, particularly on 64-bit systems where memory is aligned to 16-byte blocks, 6 bytes of padding are added. This padding ensures that the memory allocation is aligned correctly, making the total allocated memory 32 bytes, accommodating both the user-requested space and the necessary overhead for metadata and alignment.\nRequested Size: 10 bytes Total Without Alignment: 10 + 16 = 26 bytes Alignment Padding: To align to 16 bytes, we need 6 more bytes to reach 32 bytes Total Allocated Size: 32 bytes Overhead: 32 - 10 = 22 bytes Allocated Chunk Example\nAfter that heap manager mark this chunk as allocated and returns a pointer to the “User Data” region inside the chunk. which is the same return pointer you get from the malloc after the memory allocation.\nChunk Allocation Before Talking about how a Chunk is allocated lets talk about how a heap is created in the first place\nWhen malloc is called for the first time, the heap manager initiates the creation of the heap segment for the program. Initially, the operating system does not allocate any memory for the heap, but when the first memory allocation request is made, the heap manager uses system calls such as brk or sbrk to adjust the program break, effectively expanding the heap segment by allocating additional memory from the operating system. If the request is for a large amount of memory, the heap manager may use mmap to map a new memory region directly. The heap manager then initializes its internal data structures, such as free lists or bins, to manage the newly allocated heap space. This setup allows the heap to handle subsequent memory allocation and deallocation requests efficiently.\nNow lets see how the heap manager allocates the chunks.\nThere are various way a memory chunk can be allocated.\nAllocation From Free List (bins) Allocation From Top Chunk Requesting Kernel For Extra Heap Memory Using mmap for Larger Allocation Allocation From Free Lists (Bins) The heap manager has multiple free lists, also known as bins. These bins store all the chunks that are freed. The freed chunks are stored in different lists based on their size. For example, chunks larger than 512 bytes are stored in the large bin.\nWhen you request memory from the heap manager, it will search through the bins and try to find a free chunk that can fit the requested size. If the heap manager finds a chunk that is big enough to fulfill your allocation request, it will mark that chunk as allocated and return a pointer to the \u0026ldquo;User Data\u0026rdquo; area to the program. After that chunk is no longer in use and gets freed, the heap manager will add that chunk back to the free list (bin).\nAllocation From Top Chunk The top chunk is a unique feature of the GLIBC memory allocator. It represents the last free chunk in the heap and is notable for being the largest among all the chunks. This chunk can be dynamically expanded as needed. There is only one top chunk in the entire heap. If the heap manager fails to find a suitable free chunk that matches desired allocation request, then it will create a new chunk from the top chunk and resize the top chunk accordingly and allocate that newly create chunk to the program.\nRequesting Kernel For Extra Heap Memory When the heap memory is fully exhausted or there is insufficient memory available at the top chunk to allocate a large-sized chunk, the heap manager requests the kernel to add more memory to the heap, expanding its size. The heap manager expands heap memory using the sbrk system call by adjusting the program break, which defines the end of the heap. When a program requests more memory than is available within the current heap, the heap manager invokes sbrk to increase the size of the heap. This is done by moving the program break to a higher address, effectively extending the heap\u0026rsquo;s boundaries. The newly allocated memory is then used to expand the top chunk, the largest free chunk in the heap. The sbrk call increases the size of the top chunk, allowing it to accommodate new allocations. As a result, the heap grows upward, providing additional space for dynamic memory allocation, and the program can continue to request and manage memory efficiently.\nHeap Layout Before sbrk Syscall\nHeap Layout After sbrk Syscall\nUsing mmap for Larger Allocation Larger memory chunks are allocated using mmap. When a program requests a chunk of memory that exceeds the usual size limits of the heap, the heap manager uses mmap to allocate this memory outside the heap\u0026rsquo;s standard area. In the chunk metadata, which contains information about the memory block such as size and status, the M bit is set to indicate that this allocation was performed using mmap. Metadata for chunks managed by mmap includes flags that denote the allocation method and manage the block’s lifecycle. When this memory is no longer needed and is freed by the free() function, the heap manager uses munmap to return the entire mapped region of memory back to the system, ensuring that the resources are released appropriately. This separation of memory management methods helps optimize performance and manage large memory requests efficiently.\nFreeing Allocated Chunk 1. Freeing a Chunk In glibc’s ptmalloc, when a chunk of memory is freed, the allocator updates the chunk\u0026rsquo;s metadata to reflect its new status as free. This involves setting the prev_size field (which holds the size of the previous chunk) and adjusting the size field to indicate that the chunk is no longer allocated. The in_use flag is cleared to mark the chunk as available. Optionally, the allocator may zero out the chunk\u0026rsquo;s data to prevent residual data from being exposed, although this is not always performed due to performance trade-offs. Once the chunk’s metadata is updated, it is prepared for insertion into the appropriate free list or bin, based on its size and the allocator’s configuration.\n2. Adding to Free Lists/Bins After the chunk is marked as free, it is added to the appropriate free list or bin depending on its size and the state of the thread cache. If tcache is enabled and the chunk\u0026rsquo;s size matches one of the tcache size classes, the chunk is placed into the corresponding thread-specific tcache bin. This bin is part of a per-thread cache designed to reduce allocation and deallocation latency by avoiding contention with other threads. If the chunk does not fit into any tcache bin—either because it is too large or tcache is not utilized—it is added to the global free list. The global free list is organized by size classes and is used to manage free chunks that can be shared among all threads, improving scalability.\n3. Managing Free Lists Effective management of free lists involves several critical operations to optimize memory usage and reduce fragmentation. When a chunk is inserted into a free list or bin, the allocator updates its metadata to integrate the chunk into the appropriate list for its size class. The chunk is linked to other free chunks using pointers maintained in the free list’s data structure. Additionally, if the freed chunk is adjacent to other free chunks in memory, ptmalloc performs coalescing, which merges these adjacent chunks into a single larger block. This reduces fragmentation and increases the size of contiguous free memory. The allocator continuously updates its internal data structures to reflect the changes, ensuring accurate tracking of available memory and maintaining efficient allocation strategies.\nReference\nhttps://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/\nhttps://azeria-labs.com/heap-exploitation-part-2-glibc-heap-free-bins/\nhttps://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/\nhttps://codebrowser.dev/glibc/glibc/malloc/malloc.c.html\n","permalink":"http://localhost:1313/posts/heapexp2/","summary":"\u003ch3 id=\"intro\"\u003e\u003cstrong\u003eIntro\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eWelcome back to the second part of the Heap Exploitation Series. In the previous part, I provided a basic overview of glibc’s heap implementation. If you haven\u0026rsquo;t read that part yet, I highly recommend you go back and check it out to understand fundamental concepts such as chunks and bins. However, if you are already familiar with these basics, you can continue reading here. In this post, we will delve deeper into the process of memory allocation and deallocation in glibc’s heap. We’ll explore how memory is allocated for a process and the mechanisms involved in freeing memory.\u003c/p\u003e","title":"Heap Exploitation Part 2"},{"content":"Intro This is the first part of the heap exploitation series in this post i will give you an basic overview of glibc heap implementation and discuss about some basic terminologies and in the upcoming post we will take a look at how the memory allocation takes place and how it gets free and further we will look at different heap related vulnerabilities and see how to exploit them.\nWhat is Heap and Why? Heap is a type of memory used in programs to store data that needs to be dynamically allocated and can change in size during the program\u0026rsquo;s execution. The programmer can request chunk of memory from the heap and the heap manager will allocate that chunk to the program. To request a chunk of memory on heap we use malloc function and provide the size of memory that we need and it will return a pointer to that allocated chunk and using free function we can deallocate that chunk form the heap. It is very effective method for allocating memory which lives in a program for long period time and the size of the memory can be expended when its fully exhausted. You can do that using sbrk or mmap system call and when the memory is no longer needed you can free it.\nYou may be wondering why don’t we use stack it also get’s the job done.\nThink about a scenario where you have a dynamic game in which there are multiple items and your player collect those items and the size of its inventory grow. Using the heap, you can easily expand the inventory array as needed without worrying about the fixed size limitations of the stack.\nOR\nWhen the player enters a new area in the game, you might need to create 100 new enemy objects. Allocating these on the stack could quickly exhaust stack space, leading to stack overflow. The heap, on the other hand, can handle such allocations more gracefully. In some case some enemies often need to alive for entire game or for some specific amount of time. The stack is unsuitable for such long-lived objects as it is designed for temporary storage within function calls. which means when the function exits the memory allocated for those variable will be reclaimed by the stack.\nMemory layout example of x86-64 architecture\nOn a 64-bit Linux system, the stack might start at around 0x7fffffffffff and grow downwards Heap might start at around 0x600000000000 on a 64-bit system and grow upwards BSS segment addresses might be in the lower range, just above the data segment. Data segment Typically located just above the code segment Code segment might start at a fixed low address, such as 0x00400000 on a 64-bit Linux system High Memory Addresses +------------------+ | Stack | 0x7fffffffffff {Top of stack} | | | | v | | | | (grows downward) | +------------------+ | | | ^ | | | | | Heap | | (grows upward) | 0x600000000000 {Start of heap} +------------------+ | BSS Segment | +------------------+ | Data Segment | +------------------+ | Code Segment | 0x00400000 {Start of code segment} +------------------+ Low Memory Addresses History of Dynamic Memory Allocator Memory allocators are fundamental components of modern computer systems, responsible for managing dynamic memory allocation and deallocation. Over the years, several allocators have been developed, each optimized for different use cases and performance scenarios.\nOne of the earliest and most influential memory allocators was dlmalloc, developed by Doug Lea in 1987. Initially designed as a general-purpose allocator, dlmalloc became widely used due to its efficiency and portability across different systems.\nIn the early days of Linux and Unix-like systems, dlmalloc (Doug Lea\u0026rsquo;s malloc) was indeed one of the most commonly used memory allocators due to its efficiency and portability. However, the transition to ptmalloc (POSIX threads malloc) was driven by the need to support multi-threaded applications more effectively.\nThe current memory allocater used in linux is ptmalloc3 it is an evolution of the ptmalloc (POSIX threads malloc) allocator, which itself is a fork of Doug Lea\u0026rsquo;s original dlmalloc. ptmalloc3 represents a significant enhancement over its predecessors, focusing on improving performance and scalability for multi-threaded applications.\nThere are several other memory allocators created and used by different platforms\njemalloc initially created for FreeBSD, offers scalable multi-threaded memory allocation\ntcmalloc (Thread-Caching malloc), developed by Google, is optimized for performance in multi-threaded environments\nmimalloc introduced by Microsoft, focuses on compact memory usage, low latency, and high concurrency.\nArenas Arenas in ptmalloc are dedicated memory management regions assigned to individual threads within the GLIBC heap allocator. Each thread that interacts with the heap is associated with its own arena. This design allows threads to perform memory allocations and deallocations independently, minimizing contention and improving performance in multi-threaded applications. Arenas manage memory blocks and metadata specific to each thread, optimizing memory usage and reducing synchronization overhead. When a thread requests memory from the heap, it interacts solely with its designated arena, ensuring efficient and scalable memory management across concurrent threads. Multiple arenas can exist simultaneously, dynamically created and managed by ptmalloc based on the application\u0026rsquo;s threading requirements.\nThread A +----------------------------------+ | Arena A (Thread-specific) | | +-----------------------------+ | | | Memory Blocks | | | +-----------------------------+ | +----------------------------------+ Thread B +----------------------------------+ | Arena B (Thread-specific) | | +-----------------------------+ | | | Memory Blocks | | | +-----------------------------+ | +----------------------------------+ Thread C +----------------------------------+ | Arena C (Thread-specific) | | +-----------------------------+ | | | Memory Blocks | | | +-----------------------------+ | +----------------------------------+ Chunks A chunk refers to a contiguous block of memory managed by the allocator. Chunks are the fundamental units of memory that malloc manages and allocates to the program\nStrurture of malloc chunk struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size; /* Size of previous chunk (if free). */ INTERNAL_SIZE_T mchunk_size; /* Size in bytes, including overhead. */ struct malloc_chunk* fd; /* double links -- used only if free. */ struct malloc_chunk* bk; /* Only used for large blocks: pointer to next larger size. */ struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */ struct malloc_chunk* bk_nextsize; }; Whenever you call the malloc function to allocate some block of memory it simply allocate that memory and return a pointer to that allocated memory area but in reality the actual size of the chunk is grater then the requested size of the chunk. This is because the allocator need to store some metadata for managing the heap.\nFor example you requested 16 bytes of memory malloc(0x10) so the allocator will add some extra bytes to store the metadata in case of 64bit system it is 16 bytes so the actual size of the chunk is going to be :: 16 bytes(requested size) + 16 bytes(metadata) = 32 bytes(actual allocation size)\nFor 32 bit system the size will be :: 16 bytes(requested size) + 8 bytes(metadata) = 24 bytes(actual allocation size)\nChunk Metadata An allocated chunk looks like this: chunk-\u0026gt; +-------------------------------------------+ | Size of previous chunk, if unallocated | \u0026lt;-- 4 or 8 bytes +-------------------------------------------+ | Size of chunk, in bytes |A|M|P| \u0026lt;-- 4 or 8 bytes mem-\u0026gt; +-------------------------------------------+ | User data starts here... | \u0026lt;-- malloc_usable_size() bytes . . . . . | nextchunk-\u0026gt; +-------------------------------------------+ | (size of chunk, but used for application) | \u0026lt;-- 4 or 8 bytes +-------------------------------------------+ | Size of next chunk, in bytes |A|0|1| \u0026lt;-- 4 or 8 bytes +-------------------------------------------+ Each chunk begins with a field that stores the size of the previous chunk, but only if the previous chunk is unallocated. This size field is either 4 or 8 bytes, depending on the system architecture. This field helps in coalescing adjacent free chunks to reduce fragmentation.\nThe next field is the size of the current chunk, which also includes the size of its own header. This field is also either 4 or 8 bytes. Besides storing the chunk size, the least significant three bits of this field are used as flags: A, M, and P\nA (Allocated), M (Mmap), P (Previous In Use) bit fields.*\nThe A bit, found as the least significant bit of a chunk\u0026rsquo;s size field, tells whether the chunk is currently in use (1) or free (0). It\u0026rsquo;s crucial for quickly checking if memory is available for allocation or if it\u0026rsquo;s already allocated by the program.\nThe M bit, the second least significant bit, distinguishes chunks allocated via mmap (1) from those managed by the heap (0). mmap is used for larger allocations to prevent heap fragmentation by managing memory differently from typical heap allocations\nThe P bit, located as the third least significant bit, indicates if the previous chunk in memory is allocated (1) or free (0). This helps in merging adjacent free chunks to reduce fragmentation and optimize memory usage in the heap.\nAfter the metadata fields, the chunk contains space for user data. The size of this area is determined by the malloc_usable_size() function, which tells us how much space is available for the application to store its data. This is where programs store the information they need to work with.\nAfter the user data section lies the beginning of the next chunk in memory. This subsequent chunk starts with a field that serves dual purposes: it holds the size of this next chunk and, just like the current chunk\u0026rsquo;s size field, its least significant bits are used as flags. Specifically, these flags include the A flag (Allocated) indicating if the next chunk is allocated (1) or free (0), and the P flag (Previous In Use) to show if the current chunk is in use (1)\nBins The glibc memory allocator organizes free memory chunks into various bins to optimize allocation and deallocation operations. These bins—Fastbins, Tcache bins, Small bins, and Large bins—differ in their structure, usage, and efficiency, and each type has a specific number of bins designed to handle different chunk sizes.\nSmall bins handle chunks that are between 65 bytes and 512 bytes and are managed as doubly linked lists using both fd (forward) and bk (backward) pointers. There are 62 Small bins, each corresponding to a specific size class. The use of doubly linked lists allows efficient traversal and management of free chunks, although it introduces more complexity compared to the simpler Fastbins and Tcache bins.\nSmall Bins ( 65 bytes to 512 bytes) +--------------+ | Smallbin[0] | +--------------+ | v +-------------+ \u0026lt;--\u0026gt; +-------------+ \u0026lt;--\u0026gt; +-------------+ | Chunk (fd) | | Chunk (fd) | | Chunk (fd) | \u0026lt;--\u0026gt; NULL | Size A | | Size A | | Size A | +-------------+ +-------------+ +-------------+ | ... | +-------------+ | Smallbin[63]| +-------------+ | v +-------------+ \u0026lt;--\u0026gt; NULL | Chunk (fd) | | Size B | +-------------+ Fastbins are designed for very quick allocation and deallocation of small chunks, typically up to 64 bytes. Managed as singly linked lists using the fd (forward) pointer, there are 10 Fastbins (usually indexed from 0 to 9) in the array, each corresponding to a specific size class. When a chunk of memory is freed, it is added to the appropriate Fastbin list, making it available for rapid reallocation.\nFastbins ( \u0026lt;= 64 bytes) +------------+ | Fastbin[0] | +------------+ | v +-------------+ +-------------+ +-------------+ | Chunk (fd) | ---\u0026gt; | Chunk (fd) | ---\u0026gt; | Chunk (fd) | ---\u0026gt; NULL | Size A | | Size A | | Size A | +-------------+ +-------------+ +-------------+ | ... | | ... | | ... | +-------------+ +-------------+ +-------------+ | Fastbin[7] | +-------------+ | v +-------------+ +-------------+ | Chunk (fd) | ---\u0026gt; | Chunk (fd) | ---\u0026gt; NULL | Size B | | Size B | +-------------+ +-------------+ Large bins are used for chunks larger than 512 bytes and are also managed as doubly linked lists with fd and bk pointers. There are 63 Large bins, with each entry in the Largebin array corresponding to a range of chunk sizes rather than a specific size class. This approach is necessary to efficiently manage larger chunks of memory, but it also means that operations involving Large bins are typically slower and more complex due to the need to maintain sorted order and manage larger memory areas.\nLarge Bins ( \u0026gt; 512 bytes) +--------------+ | Largebin[0] | +--------------+ | v +-------------+ \u0026lt;--\u0026gt; +-------------+ | Chunk (fd) | | Chunk (fd) | \u0026lt;--\u0026gt; NULL | Size A | | Size A | +-------------+ +-------------+ | ... | +-------------+ |Largebin[127]| +-------------+ | v +-------------+ \u0026lt;--\u0026gt; NULL | Chunk (fd) | | Size B | +-------------+ Tcache bins also use singly linked lists with the fd pointer but are stored in thread-local storage to improve performance and reduce contention. There are 64 Tcache bins, each corresponding to a specific size class, similar to Fastbins, but they can hold a limited number of chunks (typically 64 per bin). This caching mechanism speeds up allocation and deallocation operations by avoiding global locks and directly accessing recently freed chunks within the same thread.\nTcache Bins ( \u0026lt;= 64 bytes) +------------+ | Tcache[0] | +------------+ | v +-------------+ +-------------+ | Chunk (fd) | ---\u0026gt; | Chunk (fd) | ---\u0026gt; NULL | Size A | | Size A | +-------------+ +-------------+ | ... | +-------------+ | Tcache[63] | +-------------+ | v +-------------+ | Chunk (fd) | ---\u0026gt; NULL | Size B | +-------------+ Unsorted bins serve as a temporary holding area for freed chunks before they are placed into the appropriate Small or Large bin. Managed as doubly linked lists with fd and bk pointers, there is only one Unsorted bin. When a chunk is freed, it is initially placed in the Unsorted bin. Later, during memory allocation, chunks from the Unsorted bin are sorted and placed into the appropriate bin based on their size. This mechanism helps to reduce fragmentation and improve the efficiency of memory allocation.\nFragmentation Heap fragmentation refers to the phenomenon where memory becomes divided into small, unusable pieces over time due to allocations and deallocations. This fragmentation can occur in both the heap managed by the operating system and within individual memory arenas managed by allocators like ptmalloc in GLIBC\nConsolidation Consolidation in the heap, refers to the process of combining fragmented memory blocks into larger contiguous blocks. This process helps reduce external fragmentation and improves the efficiency of memory usage.\nReference https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/\nhttps://pwn.college/software-exploitation/dynamic-allocator-misuse/\nhttps://elixir.bootlin.com/glibc/glibc-2.39/source/malloc/malloc.c\nhttps://0x434b.dev/overview-of-glibc-heap-exploitation-techniques/\nhttps://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/\nhttps://azeria-labs.com/heap-exploitation-part-2-glibc-heap-free-bins/\nhttps://infosecwriteups.com/the-toddlers-introduction-to-heap-exploitation-part-1-515b3621e0e8\nhttps://en.wikipedia.org/wiki/C_dynamic_memory_allocation#dlmalloc_and_ptmalloc\n","permalink":"http://localhost:1313/posts/heapexp1/","summary":"\u003ch2 id=\"intro\"\u003e\u003cstrong\u003eIntro\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eThis is the first part of the heap exploitation series in this post i will give you an basic overview of glibc heap implementation and discuss about some basic terminologies and in the upcoming post we will take a look at how the memory allocation takes place and how it gets free and further we will look at different heap related vulnerabilities and see how to exploit them.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"what-is-heap-and-why\"\u003e\u003cstrong\u003eWhat is Heap and Why?\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eHeap is a type of memory used in programs to store data that needs to be dynamically allocated and can change in size during the program\u0026rsquo;s execution. The programmer can request chunk of memory from the heap and the heap manager will allocate that chunk to the program. To request a chunk of memory on heap we use \u003cem\u003e\u003cstrong\u003emalloc\u003c/strong\u003e\u003c/em\u003e function and provide the size of memory that we need and it will return a pointer to that allocated chunk and using \u003cem\u003e\u003cstrong\u003efree\u003c/strong\u003e\u003c/em\u003e function we can deallocate that chunk form the heap. It is very effective method for allocating memory which lives in a program for long period time and the size of the memory can be expended when its fully exhausted. You can do that using \u003ca href=\"https://linux.die.net/man/2/sbrk\"\u003e\u003cem\u003e\u003cstrong\u003esbrk\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e or \u003ca href=\"https://man7.org/linux/man-pages/man2/mmap.2.html\"\u003e\u003cem\u003e\u003cstrong\u003emmap\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e system call and when the memory is no longer needed you can free it.\u003c/p\u003e","title":"Heap Exploitation Part 1"}]